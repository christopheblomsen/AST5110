{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization of a function of a single variable. Differentiation through finite differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 – Code to represent the function and the analytical and numerical derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "$$h(x) = \\cos\\left[\\frac{\\pi (x-1)}{2}\\right] \\exp\\left[-\\left(\\frac{x-3}{2.5}\\right)^2\\right],\\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $x \\in (-4,10) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a sampling of $h$ with 64 intervals, that is, 65 points, and store the\n",
    "values into double precision arrays called $xx$ and $hh$. Numpy arrays are double precision as \n",
    "default. To define $xx$ in Python you can use the commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`import numpy as np\n",
    "nump=65\n",
    "x0=-4.0 \n",
    "xf=10.0\n",
    "xx = np.arange(nump)/(nump-1.0) * (xf-x0) + x0`\n",
    "\n",
    "Use `matplotlib.pyplot` to visualize hh vs xx. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the variable $nint$ as the number of intervals ($nint= 64$ in the present case)\n",
    "and $nump$ as the number of points. In IDL, Python and C, those components go\n",
    "from the $0-$component through the component $nump−1$. Compute the ratio (1) in the [wiki](https://github.com/AST-Course/AST5110/wiki/Discretization) using and filling the function `deriv_dnw` in `nm_lib`. Feel free to use any known library or create your own functions from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will depend on how you created the function that you have $nump$ or $nump−1$ elements. If the former, the last component ($nump-1$) is ill calculated. $hp$ contains a second-order approximation to the derivative of the $hh$ function at the intermediate points $x_{i+1/2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plot $hh$ versus $xx$ as a solid line with crosses added at each grid point (to visualize the goodness of the discretization) or with `plt.hist` function combined with `plt.plot`. _Make sure the axis pixels are properly located either to the center or half grid shifted_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "\n",
    "nump = 65\n",
    "x0 = -4.0\n",
    "xf = 10.0\n",
    "\n",
    "xx = np.arange(nump)/(nump - 1.0) * (xf-x0) + x0\n",
    "\n",
    "def h(x):\n",
    "    \"\"\"\n",
    "    Equation (1) from above\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x   :   `array`\n",
    "            Spatial axis\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    `array`\n",
    "        The solution over the spatial axis\n",
    "    \"\"\"\n",
    "    ans = np.cos(np.pi*(x-1)/2)*np.exp(-((x-3)/2.5)**2)\n",
    "    return ans\n",
    "\n",
    "hh = h(xx)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(xx, hh, 'x')\n",
    "aa = plt.hist(xx, range=(x0, xf), bins=nump, weights=hh, histtype='step')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above we see the function plotted, where $x$ marks the data points, and the histogram overlayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot the array containing the numerical derivative, $hp$. Calculate analytically the derivative of the function (1) and represent it in the same figure to ascertain the goodness of the approximation for that number of points. __hint__ _make sure the axis pixels are properly located either to the center or half grid shifted_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dh(xx):\n",
    "    \"\"\"\n",
    "    The analytical derivate of h(x)\n",
    "    # Hand calculations were wrong\n",
    "    u = np.cos(np.pi*(xx-1)/2)\n",
    "    v = np.exp(-((xx-3)/2.5)**2)\n",
    "    \n",
    "    du = - np.pi/2 * np.sin(np.pi*(xx - 1)/2)\n",
    "    dv = - 2*((xx-3)/2.5)*(1/2.5)*np.exp(- ((xx-3)/2.5)**2)\n",
    "    \n",
    "    ans = du*v + v*dv\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xx  :   `array`\n",
    "            Spatial axis\n",
    "    \"\"\"\n",
    "    # Wolfram alpha\n",
    "    ans = np.exp( -0.16 * (-3 + xx)**2) * (1.5708 * np.cos((np.pi*xx) / 2) - (-0.96 + 0.32 * xx) * np.sin((np.pi * xx) / 2))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nm_lib import nm_lib as nm\n",
    "importlib.reload(nm)\n",
    "\n",
    "dx = (xx[1] - xx[0])\n",
    "\n",
    "y = nm.deriv_dnw(xx, h(xx))\n",
    "y_exact = dh(xx)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(xx, y, 'x', label='numerical')\n",
    "plt.plot(xx, y_exact, label='exact')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above I plot the exact solution of the derivative against the numerical approximation marked with $x$. To account for the shift, I subtracted $dx/2$ from the analytical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Repeat the foregoing, but now using $nint= 32$ and $nint= 16$ intervals to see how the approximation deteriorates. Thereafter, repeat the same process for 128 and 256 intervals, to see how it improves. Consider to use `plt.semilogy` for the error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15,12))\n",
    "\n",
    "for nint in [16, 32, 128, 256]:\n",
    "    nump = nint + 1\n",
    "    xx = np.arange(nump)/(nint) * (xf - x0) + x0\n",
    "    \n",
    "    dx = xx[1] - xx[0]\n",
    "\n",
    "    y = nm.deriv_dnw(xx, h(xx))\n",
    "    y_exact = dh(xx)\n",
    "\n",
    "    ax[i, j].set_title(f'nint={nint}')\n",
    "    ax[i, j].plot(xx, y, 'x', label='Numerical')\n",
    "    ax[i, j].plot(xx, y_exact, label='Exact')\n",
    "    ax[i, j].legend()\n",
    "    \n",
    "    j += 1\n",
    "    if j == 2:\n",
    "        i += 1\n",
    "        j = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,12))\n",
    "mean = []\n",
    "nint_list = [16, 32, 128, 256]\n",
    "\n",
    "for nint in [16, 32, 128, 256]:\n",
    "    nump = nint + 1\n",
    "    xx = np.arange(nump)/(nint) * (xf - x0) + x0\n",
    "    \n",
    "    dx = xx[1] - xx[0]\n",
    "\n",
    "    y = nm.deriv_dnw(xx, h(xx))\n",
    "    y_exact = dh(xx-dx/2)\n",
    "    diff = np.mean(abs(y - y_exact))\n",
    "    mean.append(diff)\n",
    "    ax.semilogy(xx, abs(y-y_exact), label=f'nint {nint}')\n",
    "    ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.ylabel('abs error')\n",
    "plt.xlabel(\"nint\")\n",
    "plt.semilogy(nint_list, mean, '-x')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the two above plots we observe first that the absolute error goes down quadraticly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Test of the quadratic order of the approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to test if the ratio $(h_{i+1}-h_i)/(x_{i+1}-x_i)$ approaches the analytical value of the derivative. To that end, we will use samplings with, successively, 16, 32, 64, 128, 256, 512 and 1024 intervals (which are successive powers of 2). Calculate the maximum of the absolute value of the error, meaning: the difference between the analytical and the numerical derivatives at the _same points_. Plot a graph of that value versus the size of the interval in each case using a diagram with logarithmic axes. Check if the curve you get corresponds to a quadratic dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nint = 32\n",
    "nump = 33\n",
    "\n",
    "fig, ax = plt.subplots(7, 1, figsize=(12, 17))\n",
    "\n",
    "l = 0\n",
    "mean = []\n",
    "for i in range(4, 11):\n",
    "    diff = []\n",
    "    nint = 2**i\n",
    "    nump = nint + 1\n",
    "\n",
    "    xx = np.arange(nump)/(nint) * (xf - x0) + x0\n",
    "    hh = h(xx)\n",
    "    dhh = dh(xx)\n",
    "    for j in range(len(xx)-1):\n",
    "        ans = (hh[j+1] - hh[j])/(xx[j+1] - xx[j])\n",
    "        diff.append(ans)\n",
    "    mean.append(np.mean(abs(dhh[:-1] - diff)))\n",
    "    ax[l].set_title(f'Ratio difference for {nint}')\n",
    "    ax[l].plot(xx[:-1], diff, label='Ratio')\n",
    "    ax[l].plot(xx, dhh, label='Numerical diff')\n",
    "    ax[l].legend()\n",
    "    \n",
    "    l += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above plot we observe that for higher `nint` the approximation gets better and better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nint_list = [2**i for i in range(4, 11)]\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.ylabel('abs error')\n",
    "plt.xlabel(\"nint\")\n",
    "\n",
    "plt.loglog(nint_list, mean, '-x')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above plot is logarithmic and we see that it goes linearly on that scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 17))\n",
    "l = 0\n",
    "mean = []\n",
    "\n",
    "for i in range(4, 11):\n",
    "    nint = 2**i\n",
    "    nump = nint + 1\n",
    "    xx = np.arange(nump)/(nint) * (xf - x0) + x0\n",
    "    \n",
    "    dx = xx[1] - xx[0]\n",
    "\n",
    "    y = nm.deriv_dnw(xx, h(xx))\n",
    "    y_exact = dh(xx-dx/2)\n",
    "    \n",
    "    mean.append(np.mean(abs(y-y_exact)))\n",
    "\n",
    "    ax.set_title(f'nint={nint}')\n",
    "    ax.semilogy(xx, abs(y-y_exact), label='Abs error')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nint_list = [2**i for i in range(4, 11)]\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.ylabel('abs error')\n",
    "plt.xlabel(\"nint\")\n",
    "\n",
    "plt.loglog(nint_list, mean, '-x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Improving the accuracy of the test of the quadratic order of the approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the accuracy of the result of the previous paragraph:\n",
    "\n",
    "1. extend the test to a larger range of number of intervals (including 2048, 4096, 8192, 16384). Make sure to use double precision variables throughout the program (meaning: all variables except the array indices).\n",
    "\n",
    "2. then try to fit a straight to the logarithm of the error curves using Python program `numpy.polyfit` and `numpy.poly1d`. From the value of the slope you get from that program, check the accuracy with which you obtain the quadratic dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 17))\n",
    "\n",
    "abs_err = []\n",
    "dxs = []\n",
    "polyfit = []\n",
    "\n",
    "for i in range(4, 15):\n",
    "    nint = np.double(2**i)\n",
    "    nump = np.double(nint + 1)\n",
    "    xx = np.double(np.arange(nump)/(nint) * (xf - x0) + x0)\n",
    "    \n",
    "    dx = np.double(xx[1] - xx[0])\n",
    "\n",
    "    y = np.double(nm.deriv_dnw(xx, h(xx)))\n",
    "    y_exact = np.double(dh(xx-dx/2))\n",
    "    \n",
    "    diff = np.abs(y-y_exact)\n",
    "    abs_err.append(np.mean(diff[1:]))\n",
    "    dxs.append(dx)\n",
    "\n",
    "    ax.set_title(f'nint={nint}')\n",
    "    ax.semilogy(xx, diff, 'x', label=f'nint: {nint}')\n",
    "    ax.legend()\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.polyfit(np.log10(dxs[:-3]), np.log10(abs_err[:-3]), deg=1)\n",
    "p = np.poly1d(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.logspace(11, 15, base=10)\n",
    "print(len(abs_err))\n",
    "nint_list = [2**i for i in range(4, 15)]\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.ylabel('abs error')\n",
    "plt.xlabel(\"dx\")\n",
    "plt.plot(np.log10(dxs), p(np.log10(dxs)))\n",
    "for i in range(len(abs_err)):\n",
    "    plt.plot(np.log10(dxs[i]), np.log10(abs_err[i]), '-x', label=f'nint: {nint_list[i]}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where we see that the coefficient to $x$ is close to 2 which is the quadratic dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Analytical proof of the order of convergence of the approximation for the derivative (optional)\n",
    "\n",
    "Consider the sampling used in exercise this, assuming that the spacing between grid points is uniform, i.e., $(\\Delta x)_i = \\Delta x$. Write a formal Taylor expansion as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x_{i+1}) = f(x_{i+1/2}) + f'(x_{i+1/2})\\frac{\\Delta x}{2} + ...  \\tag{2}$$\n",
    "\n",
    "$$f(x_{i}) = f(x_{i+1/2}) - f'(x_{i+1/2})\\frac{\\Delta x}{2} + ...  \\tag{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "including terms up to order $(\\Delta x)^3$. Eliminating terms combining those two expressions, conclude that, as said in the previous exercise sheet, the finite-difference approximation to the derivative at the midpoints $x_{i+1/2}$ carried out there is of 2nd order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
